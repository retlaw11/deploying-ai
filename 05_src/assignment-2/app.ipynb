{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9db6f5cf",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b211d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/retlawair/Desktop/deploying-ai/deploying-ai-env/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ All packages installed!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages using pip magic command (best for Jupyter)\n",
    "%pip install -q gradio openai python-dotenv\n",
    "\n",
    "print(\"‚úÖ All packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c5098",
   "metadata": {},
   "source": [
    "## Step 2: Load Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a4b18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded: YTLIZ27JW0...\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../../05_src/.secrets\n",
    "\n",
    "import os\n",
    "api_key = os.getenv('API_GATEWAY_KEY')\n",
    "print(f\"‚úÖ API Key loaded: {api_key[:10] if api_key else 'NOT FOUND'}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43dbd91",
   "metadata": {},
   "source": [
    "## Step 3: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d1815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gradio 5.49.1\n",
      "‚úÖ OpenAI SDK ready\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"‚úÖ Gradio {gr.__version__}\")\n",
    "print(\"‚úÖ OpenAI SDK ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "823aaab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pydantic models ready\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import Optional, List, Literal\n",
    "from enum import Enum\n",
    "\n",
    "print(\"‚úÖ Pydantic models ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9803fd",
   "metadata": {},
   "source": [
    "## Step 4: Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b32078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI(\n",
    "    default_headers={\"x-api-key\": os.getenv('API_GATEWAY_KEY')},\n",
    "    base_url='https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52ecb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pydantic models and PersonalityLibrary defined\n"
     ]
    }
   ],
   "source": [
    "# Define allowed values as enums for type safety\n",
    "class ToneType(str, Enum):\n",
    "    FORMAL = \"formal\"\n",
    "    CASUAL = \"casual\"\n",
    "    FRIENDLY = \"friendly\"\n",
    "    PROFESSIONAL = \"professional\"\n",
    "    HUMOROUS = \"humorous\"\n",
    "\n",
    "class StyleType(str, Enum):\n",
    "    CONCISE = \"concise\"\n",
    "    DETAILED = \"detailed\"\n",
    "    CREATIVE = \"creative\"\n",
    "    ANALYTICAL = \"analytical\"\n",
    "    SOCRATIC = \"socratic\"\n",
    "\n",
    "class RoleType(str, Enum):\n",
    "    ASSISTANT = \"helpful AI assistant\"\n",
    "    MENTOR = \"mentor and educator\"\n",
    "    EXPERT = \"subject matter expert\"\n",
    "    BRAINSTORMER = \"creative brainstorming partner\"\n",
    "    THERAPIST = \"empathetic listener\"\n",
    "    ANALYST = \"data analyst\"\n",
    "\n",
    "# Core configuration model\n",
    "class ChatConfig(BaseModel):\n",
    "    \"\"\"Pydantic model for chat personality and behavior configuration\"\"\"\n",
    "    \n",
    "    tone: ToneType = Field(\n",
    "        default=ToneType.FRIENDLY,\n",
    "        description=\"The tone of voice for responses\"\n",
    "    )\n",
    "    conversational_style: StyleType = Field(\n",
    "        default=StyleType.CONCISE,\n",
    "        description=\"How detailed or creative responses should be\"\n",
    "    )\n",
    "    role: RoleType = Field(\n",
    "        default=RoleType.ASSISTANT,\n",
    "        description=\"The character role the AI adopts\"\n",
    "    )\n",
    "    temperature: float = Field(\n",
    "        default=0.7,\n",
    "        ge=0.0,\n",
    "        le=2.0,\n",
    "        description=\"Controls randomness (0=deterministic, 2=very creative)\"\n",
    "    )\n",
    "    max_tokens: int = Field(\n",
    "        default=1000,\n",
    "        ge=100,\n",
    "        le=4000,\n",
    "        description=\"Maximum response length\"\n",
    "    )\n",
    "    custom_system_prompt: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Override default system prompt\"\n",
    "    )\n",
    "    model: str = Field(\n",
    "        default=\"gpt-4o-mini\",\n",
    "        description=\"OpenAI model to use\"\n",
    "    )\n",
    "    \n",
    "    @field_validator('temperature')\n",
    "    @classmethod\n",
    "    def validate_temperature(cls, v):\n",
    "        if v < 0 or v > 2:\n",
    "            raise ValueError('Temperature must be between 0 and 2')\n",
    "        return v\n",
    "    \n",
    "    def get_system_prompt(self) -> str:\n",
    "        \"\"\"Generate comprehensive system prompt based on configuration\"\"\"\n",
    "        if self.custom_system_prompt:\n",
    "            return self.custom_system_prompt\n",
    "        \n",
    "        return f\"\"\"You are a {self.role.value} with a {self.tone.value} tone.\n",
    "Your conversational style is {self.conversational_style.value}.\n",
    "\n",
    "Guidelines:\n",
    "- Maintain consistency with your assigned tone throughout\n",
    "- Adapt your response length based on your style (concise = short, detailed = thorough)\n",
    "- Stay in character as a {self.role.value}\n",
    "- Be helpful, accurate, and respectful\"\"\"\n",
    "    \n",
    "    class Config:\n",
    "        use_enum_values = True\n",
    "\n",
    "# Message model for type-safe message handling\n",
    "class Message(BaseModel):\n",
    "    role: Literal[\"system\", \"user\", \"assistant\"]\n",
    "    content: str\n",
    "\n",
    "# Chat session model to track state\n",
    "class ChatSession(BaseModel):\n",
    "    config: ChatConfig\n",
    "    messages: List[Message] = Field(default_factory=list)\n",
    "    \n",
    "    def add_message(self, role: str, content: str):\n",
    "        \"\"\"Add message to session\"\"\"\n",
    "        self.messages.append(Message(role=role, content=content))\n",
    "    \n",
    "    def get_messages_for_api(self) -> List[dict]:\n",
    "        \"\"\"Convert messages to OpenAI API format\"\"\"\n",
    "        return [{\"role\": msg.role, \"content\": msg.content} for msg in self.messages]\n",
    "\n",
    "# Predefined personality configurations\n",
    "class PersonalityLibrary:\n",
    "    \"\"\"Collection of pre-configured chat personalities\"\"\"\n",
    "    \n",
    "    DEFAULT = ChatConfig(\n",
    "        tone=ToneType.FRIENDLY,\n",
    "        conversational_style=StyleType.CONCISE,\n",
    "        role=RoleType.ASSISTANT,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    MENTOR = ChatConfig(\n",
    "        tone=ToneType.PROFESSIONAL,\n",
    "        conversational_style=StyleType.DETAILED,\n",
    "        role=RoleType.MENTOR,\n",
    "        temperature=0.6\n",
    "    )\n",
    "    \n",
    "    CREATIVE = ChatConfig(\n",
    "        tone=ToneType.CASUAL,\n",
    "        conversational_style=StyleType.CREATIVE,\n",
    "        role=RoleType.BRAINSTORMER,\n",
    "        temperature=0.9\n",
    "    )\n",
    "    \n",
    "    ANALYTICAL = ChatConfig(\n",
    "        tone=ToneType.FORMAL,\n",
    "        conversational_style=StyleType.ANALYTICAL,\n",
    "        role=RoleType.ANALYST,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_personalities():\n",
    "        \"\"\"Return all available personalities\"\"\"\n",
    "        return {\n",
    "            \"default\": PersonalityLibrary.DEFAULT,\n",
    "            \"mentor\": PersonalityLibrary.MENTOR,\n",
    "            \"creative\": PersonalityLibrary.CREATIVE,\n",
    "            \"analytical\": PersonalityLibrary.ANALYTICAL\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Pydantic models and PersonalityLibrary defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d93c7",
   "metadata": {},
   "source": [
    "## Step 4.5: Define Chat Configuration Models with Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3ace14",
   "metadata": {},
   "source": [
    "## Step 5: Define Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b36abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced chat function defined with Pydantic config\n"
     ]
    }
   ],
   "source": [
    "def chat_with_gpt(message, history, config=None):\n",
    "    \"\"\"\n",
    "    Enhanced chat with GPT-4 using Pydantic configuration management.\n",
    "    Maintains conversation history with configurable personality.\n",
    "    \n",
    "    Args:\n",
    "        message: Current user message (string)\n",
    "        history: List of message dictionaries with 'role' and 'content' keys\n",
    "        config: ChatConfig Pydantic model (uses DEFAULT if None)\n",
    "    \n",
    "    Returns:\n",
    "        Assistant's response (string)\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = PersonalityLibrary.DEFAULT\n",
    "    \n",
    "    try:\n",
    "        # Validate and ensure config is ChatConfig instance\n",
    "        if not isinstance(config, ChatConfig):\n",
    "            config = ChatConfig(**config) if isinstance(config, dict) else PersonalityLibrary.DEFAULT\n",
    "        \n",
    "        # Build messages list with system prompt and history\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": config.get_system_prompt()\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Add conversation history (already in correct format)\n",
    "        if history:\n",
    "            messages.extend(history)\n",
    "        \n",
    "        # Add current message\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        # Call OpenAI API with validated config\n",
    "        response = client.chat.completions.create(\n",
    "            model=config.model,\n",
    "            messages=messages,\n",
    "            temperature=config.temperature,\n",
    "            max_tokens=config.max_tokens\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Enhanced chat function defined with Pydantic config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8bd9e",
   "metadata": {},
   "source": [
    "## Step 6: Create Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69847dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Chatbot interface created\n"
     ]
    }
   ],
   "source": [
    "# Store config choices\n",
    "config_choices = {\n",
    "    \"personality\": \"default\",\n",
    "    \"tone\": \"friendly\", \n",
    "    \"style\": \"concise\",\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "def simple_chat(message, history):\n",
    "    \"\"\"Simple chat function that reads from config_choices\"\"\"\n",
    "    try:\n",
    "        # Get base config from personality\n",
    "        personalities = PersonalityLibrary.get_all_personalities()\n",
    "        base_config = personalities.get(config_choices[\"personality\"], PersonalityLibrary.DEFAULT)\n",
    "        \n",
    "        # Use selected tone and style directly as strings\n",
    "        tone_str = config_choices[\"tone\"]\n",
    "        style_str = config_choices[\"style\"]\n",
    "        \n",
    "        # Create simple system prompt with selected attributes\n",
    "        system_prompt = f\"\"\"You are a helpful AI assistant with a {tone_str} tone.\n",
    "Your conversational style is {style_str}.\n",
    "Be helpful, accurate, and respectful.\"\"\"\n",
    "        \n",
    "        # Build messages\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        if history:\n",
    "            messages.extend(history)\n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "        \n",
    "        # Call API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=config_choices[\"temperature\"],\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# ü§ñ Walter's AI Chatbot\")\n",
    "    gr.Markdown(\"Customize your chat experience with different personalities and settings\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        personality = gr.Dropdown(\n",
    "            choices=list(PersonalityLibrary.get_all_personalities().keys()),\n",
    "            value=\"default\",\n",
    "            label=\"üé≠ Personality\"\n",
    "        )\n",
    "        tone = gr.Dropdown(\n",
    "            choices=[t.value for t in ToneType],\n",
    "            value=\"friendly\",\n",
    "            label=\"üéµ Tone\"\n",
    "        )\n",
    "        style = gr.Dropdown(\n",
    "            choices=[s.value for s in StyleType],\n",
    "            value=\"concise\",\n",
    "            label=\"üìù Style\"\n",
    "        )\n",
    "        temperature = gr.Slider(\n",
    "            minimum=0.0,\n",
    "            maximum=2.0,\n",
    "            value=0.7,\n",
    "            step=0.1,\n",
    "            label=\"üî• Temperature\"\n",
    "        )\n",
    "    \n",
    "    personality.change(lambda x: config_choices.update({\"personality\": x}), inputs=personality)\n",
    "    tone.change(lambda x: config_choices.update({\"tone\": x}), inputs=tone)\n",
    "    style.change(lambda x: config_choices.update({\"style\": x}), inputs=style)\n",
    "    temperature.change(lambda x: config_choices.update({\"temperature\": x}), inputs=temperature)\n",
    "    \n",
    "    chatbot = gr.ChatInterface(\n",
    "        fn=simple_chat,\n",
    "        examples=[\n",
    "            \"What is machine learning?\",\n",
    "            \"Explain quantum computing\",\n",
    "            \"How do neural networks work?\",\n",
    "            \"What is the capital of France?\"\n",
    "        ],\n",
    "        type=\"messages\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Chatbot interface created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abd250b",
   "metadata": {},
   "source": [
    "## Step 7: Launch the Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cddabfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                   üöÄ LAUNCHING CHATBOT APPLICATION                    \n",
      "======================================================================\n",
      "\n",
      "üì± Open your browser and navigate to: http://localhost:7860\n",
      "\n",
      "‚ú® Features:\n",
      "   ‚Ä¢ Full conversation history\n",
      "   ‚Ä¢ Real-time responses from GPT-4\n",
      "   ‚Ä¢ Beautiful, responsive interface\n",
      "   ‚Ä¢ One-click chat management\n",
      "\n",
      "‚èπÔ∏è  Press Ctrl+C in terminal to stop\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the Gradio app\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ LAUNCHING CHATBOT APPLICATION\".center(70))\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"üì± Open your browser and navigate to: http://localhost:7860\")\n",
    "print()\n",
    "print(\"‚ú® Features:\")\n",
    "print(\"   ‚Ä¢ Full conversation history\")\n",
    "print(\"   ‚Ä¢ Real-time responses from GPT-4\")\n",
    "print(\"   ‚Ä¢ Beautiful, responsive interface\")\n",
    "print(\"   ‚Ä¢ One-click chat management\")\n",
    "print()\n",
    "print(\"‚èπÔ∏è  Press Ctrl+C in terminal to stop\")\n",
    "print()\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Launch\n",
    "demo.launch(\n",
    "    share=False,\n",
    "    server_name=\"127.0.0.1\",\n",
    "    server_port=None,\n",
    "    show_error=True,\n",
    "    quiet=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
